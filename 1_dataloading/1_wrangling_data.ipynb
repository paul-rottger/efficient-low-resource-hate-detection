{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13adda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from html import unescape\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbcb7d-80d9-42c9-b391-cf6e785ae5eb",
   "metadata": {},
   "source": [
    "## Load raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751cc58c-ca94-42c7-b1bd-a1d1e23ebdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynabench2021_english.csv\n",
      "ousidhoum2019_french.csv\n",
      "fortuna2019_portuguese.csv\n",
      "basile2019_spanish.csv\n",
      "ousidhoum2019_arabic.csv\n",
      "sanguinetti2020_italian.csv\n"
     ]
    }
   ],
   "source": [
    "df_dict = dict()\n",
    "\n",
    "PATH = \"./data/0_raw\"\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if \"ipynb\" not in file:\n",
    "        print(file)\n",
    "        df_dict[file.removesuffix(\".csv\")] = pd.read_csv(f\"{PATH}/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7ed05-5188-48b5-a2ca-338ebadd806b",
   "metadata": {},
   "source": [
    "## Reformat columns\n",
    "Need separate logic for different datasets. 1 is for hateful, 0 for non-hateful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13277bd-80b3-4664-854c-9067973ff9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynabench 2021 / English\n",
    "df_dict[\"dynabench2021_english\"].label.replace({\"hate\":1, \"nothate\":0}, inplace=True)\n",
    "\n",
    "# Fortuna 2019 / Portuguese\n",
    "df_dict[\"fortuna2019_portuguese\"].rename(columns={\"hatespeech_comb\": \"label\"}, inplace=True)\n",
    "\n",
    "# Basile 2019 / Spanish\n",
    "df_dict[\"basile2019_spanish\"].rename(columns={\"HS\": \"label\"}, inplace=True)\n",
    "\n",
    "# Sanguinetti 2020 / Italian\n",
    "df_dict[\"sanguinetti2020_italian\"].rename(columns={\"hs\": \"label\"}, inplace=True)\n",
    "\n",
    "# Ousidhoum 2019 / Arabic & French\n",
    "for d in [\"ousidhoum2019_arabic\", \"ousidhoum2019_french\"]:\n",
    "    df_dict[d][\"label\"] = df_dict[d].sentiment.apply(lambda x: 1 if \"hateful\" in x else 0)\n",
    "    # text was already cleaned in a way that conflicts with our later cleaning, so we align it here\n",
    "    df_dict[d][\"text\"] = df_dict[d].tweet.apply(lambda x: x.replace(\"@url\", \"http\"))\n",
    "    \n",
    "# drop redundant columns\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset] = df_dict[dataset][[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb486c0-6d69-47de-ab40-1395cff48b78",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f2180b-49b9-4337-8bf6-918ae0fff373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = unescape(text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_-]+\",'@user',text)\n",
    "    text = re.sub(r\"http\\S+\",'http',text)\n",
    "    text = re.sub(r\"\\n\",' ',text)\n",
    "    text = re.sub(r\"\\t\",' ',text)\n",
    "    text = text.replace(\"[URL]\", \"http\")\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset][\"text\"] = df_dict[dataset].text.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f11a2-57a3-4f6e-85d8-1e9964695e8a",
   "metadata": {},
   "source": [
    "## Show descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf6ea87-7c69-4ead-88e6-7dd675650ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DYNABENCH2021_ENGLISH\n",
      "41144 entries, of which 22175 (53.90%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20623</th>\n",
       "      <td>Women are so fucking self centered and incapable of seeing the bigger picture. Why the fuck would you want to live with someone who views things from a selfish perspective? It sucks. You want to know why it sucks? Because women.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35912</th>\n",
       "      <td>gays are vile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791</th>\n",
       "      <td>youre a cotton picker! what the fuck even is that? That's an 18th century fucking insult boi and you stop me calling that, I'll break your face</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21865</th>\n",
       "      <td>Zyklon b is just a dezinfectant though not a deadly virus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>I adore you man, you are just anti-nigga as I am</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                       text  \\\n",
       "20623  Women are so fucking self centered and incapable of seeing the bigger picture. Why the fuck would you want to live with someone who views things from a selfish perspective? It sucks. You want to know why it sucks? Because women.   \n",
       "35912                                                                                                                                                                                                                         gays are vile   \n",
       "9791                                                                                        youre a cotton picker! what the fuck even is that? That's an 18th century fucking insult boi and you stop me calling that, I'll break your face   \n",
       "21865                                                                                                                                                                             Zyklon b is just a dezinfectant though not a deadly virus   \n",
       "6218                                                                                                                                                                                       I adore you man, you are just anti-nigga as I am   \n",
       "\n",
       "       label  \n",
       "20623      1  \n",
       "35912      1  \n",
       "9791       1  \n",
       "21865      0  \n",
       "6218       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUSIDHOUM2019_FRENCH\n",
      "4014 entries, of which 399 (9.94%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>putain d'attardé</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>@user @user @user mdr les renois qui like fort les insultes vous voit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>@user sans emploie hhhhh. c'est un rebeu qui lui pris ça place. quelle grosse merde. de toute façon les fachos… http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>@user ils se sont cru dans un film juste des gars un peut attardé un peut trop influencé par les films/virtuel… http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>mdrr le mec parle des bites de noirs ça se voit il connaît pas les teubs des rebeus — bon ça est mdrrrr stop http</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text  \\\n",
       "3055                                                                                                      putain d'attardé   \n",
       "1427                                                 @user @user @user mdr les renois qui like fort les insultes vous voit   \n",
       "3446  @user sans emploie hhhhh. c'est un rebeu qui lui pris ça place. quelle grosse merde. de toute façon les fachos… http   \n",
       "1259  @user ils se sont cru dans un film juste des gars un peut attardé un peut trop influencé par les films/virtuel… http   \n",
       "1790     mdrr le mec parle des bites de noirs ça se voit il connaît pas les teubs des rebeus — bon ça est mdrrrr stop http   \n",
       "\n",
       "      label  \n",
       "3055      0  \n",
       "1427      0  \n",
       "3446      0  \n",
       "1259      0  \n",
       "1790      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FORTUNA2019_PORTUGUESE\n",
      "5670 entries, of which 1788 (31.53%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>RT @user: eu toda vez que vejo alguém falando que racismo inverso existe http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>@user dá uma fuçada lá, mãe, primeiro livro da minha amiga @user www.aescritoraeomusico.blogspot.com (eu reviso)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>RT @user @user nao paga pau. Ele paga uma mocreia para tirar a zica.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>@user hahahah  Só 3 maconheiras vaiam o Mito: vira notícia; E isso aqui, G1?http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>BOA PRELIMINAR, MAS AGORA A GERAÇÃO CREME DE AVELÃ EMOCIONADA PODE SE RETIRAR: VAI COMEÇAR FUTEBOL DE VERDADE: LIBERTADORES E COPA DO BRASIL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              text  \\\n",
       "3886                                                                 RT @user: eu toda vez que vejo alguém falando que racismo inverso existe http   \n",
       "1832                              @user dá uma fuçada lá, mãe, primeiro livro da minha amiga @user www.aescritoraeomusico.blogspot.com (eu reviso)   \n",
       "4519                                                                          RT @user @user nao paga pau. Ele paga uma mocreia para tirar a zica.   \n",
       "1924                                                              @user hahahah  Só 3 maconheiras vaiam o Mito: vira notícia; E isso aqui, G1?http   \n",
       "659   BOA PRELIMINAR, MAS AGORA A GERAÇÃO CREME DE AVELÃ EMOCIONADA PODE SE RETIRAR: VAI COMEÇAR FUTEBOL DE VERDADE: LIBERTADORES E COPA DO BRASIL   \n",
       "\n",
       "      label  \n",
       "3886      0  \n",
       "1832      0  \n",
       "4519      1  \n",
       "1924      0  \n",
       "659       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASILE2019_SPANISH\n",
      "6600 entries, of which 2739 (41.50%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>@user Me enseñaron que a los hijos de puta como tú hay que dejarlos bien muertos.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>@user Ella es más bonita, tú eres más perra.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Putos moros se están cargando el pais. http</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>@user @user @user Tu no te mereces q yo me esfuerce en poner ni una #puta coma para q te ahogues al leer #bastardo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>@user @user tu eres diamante zorra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    text  \\\n",
       "2822                                   @user Me enseñaron que a los hijos de puta como tú hay que dejarlos bien muertos.   \n",
       "1863                                                                        @user Ella es más bonita, tú eres más perra.   \n",
       "358                                                                          Putos moros se están cargando el pais. http   \n",
       "739   @user @user @user Tu no te mereces q yo me esfuerce en poner ni una #puta coma para q te ahogues al leer #bastardo   \n",
       "5293                                                                                  @user @user tu eres diamante zorra   \n",
       "\n",
       "      label  \n",
       "2822      0  \n",
       "1863      1  \n",
       "358       1  \n",
       "739       0  \n",
       "5293      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUSIDHOUM2019_ARABIC\n",
      "3353 entries, of which 755 (22.52%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>تخيل بنفس الوقت تكلم خنزير بالواقع ويسبك سبودر بالخاص ويمنشنك وسيف ؟ اي انحطاط توصلت له يا انا</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>@user هؤلاء مجرد أنعام، كرم الله الأنعام، وأنما خنازير بشريه، مأكلها خبيث ومشربها خبيث، ومسكنها خبيث، ول… http</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>ترى شكلج غبي وانتي تستنقصين من بنات جنسج وتدافعين عن الشباب وتبررين لهم التحرش بحجة ان البنت مب متحجبة او تسوي شوو!… http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>@user @user خنزير يرتوت لخنزير</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>من أول انطباع تعرف أنه ازق من مر على النادي بعد خنزير اليونايتد http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                           text  \\\n",
       "2381                             تخيل بنفس الوقت تكلم خنزير بالواقع ويسبك سبودر بالخاص ويمنشنك وسيف ؟ اي انحطاط توصلت له يا انا   \n",
       "2842             @user هؤلاء مجرد أنعام، كرم الله الأنعام، وأنما خنازير بشريه، مأكلها خبيث ومشربها خبيث، ومسكنها خبيث، ول… http   \n",
       "2077  ترى شكلج غبي وانتي تستنقصين من بنات جنسج وتدافعين عن الشباب وتبررين لهم التحرش بحجة ان البنت مب متحجبة او تسوي شوو!… http   \n",
       "430                                                                                              @user @user خنزير يرتوت لخنزير   \n",
       "2188                                                       من أول انطباع تعرف أنه ازق من مر على النادي بعد خنزير اليونايتد http   \n",
       "\n",
       "      label  \n",
       "2381      0  \n",
       "2842      1  \n",
       "2077      0  \n",
       "430       0  \n",
       "2188      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SANGUINETTI2020_ITALIAN\n",
      "8100 entries, of which 3388 (41.83%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>@user @user Vallo a dire alla protettrice dei rom, Diana Pavlovic! ������</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>NESSUNO È STATO BUTTATO PER STRADATUTTE STRONZATEIL DECRETO SALVINI ATTACCA GLI INTERESSI DELL'IMMIGRAZIONE CLANDESTINACHE COSTA MILIONI DI EURO AL GIORNOAGLI ITALIANI.Decreto Salvini: a chi fa paura il ritorno della legalità? http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>Trovano una #rom in casa a rubare ma non la denunciano xchè temono ritorsioni da parte dei #rom http succede in #Italia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>Ma guarda. L’Autorità Marittima di #Panama ha comunicato ha avviato il processo di cancellazione dal proprio registro navale della #Aquarius di @user e @user  perché “non tiene conto delle procedure legali internazionali sul recupero degli immigrati nel Mediterraneo”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>Dal campo rom di Castel Romano alla Capitale per rubare portafogli: arrestate due donne ‘in trasferta’ http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                              text  \\\n",
       "1664                                                                                                                                                                                                     @user @user Vallo a dire alla protettrice dei rom, Diana Pavlovic! ������   \n",
       "6799                                       NESSUNO È STATO BUTTATO PER STRADATUTTE STRONZATEIL DECRETO SALVINI ATTACCA GLI INTERESSI DELL'IMMIGRAZIONE CLANDESTINACHE COSTA MILIONI DI EURO AL GIORNOAGLI ITALIANI.Decreto Salvini: a chi fa paura il ritorno della legalità? http   \n",
       "2691                                                                                                                                                       Trovano una #rom in casa a rubare ma non la denunciano xchè temono ritorsioni da parte dei #rom http succede in #Italia   \n",
       "4782  Ma guarda. L’Autorità Marittima di #Panama ha comunicato ha avviato il processo di cancellazione dal proprio registro navale della #Aquarius di @user e @user  perché “non tiene conto delle procedure legali internazionali sul recupero degli immigrati nel Mediterraneo”.   \n",
       "1923                                                                                                                                                                   Dal campo rom di Castel Romano alla Capitale per rubare portafogli: arrestate due donne ‘in trasferta’ http   \n",
       "\n",
       "      label  \n",
       "1664      0  \n",
       "6799      0  \n",
       "2691      0  \n",
       "4782      0  \n",
       "1923      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def descriptive_stats(df):\n",
    "    n_total = df.shape[0]\n",
    "    n_hate = df.label.sum()\n",
    "    print(\"{} entries, of which {} ({:.2%}) are hateful.\".format(n_total, n_hate, n_hate/n_total))\n",
    "    return df.label.sum()/len(df), len(df)\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset.upper())\n",
    "    descriptive_stats(df_dict[dataset])\n",
    "    display(df_dict[dataset].sample(5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c79d7f-8abc-4b7b-957d-073051f468fe",
   "metadata": {},
   "source": [
    "## Create and export splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d2e82a-460f-4fe4-b777-fe34ae08c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside 2.5k from each dataset for testing\n",
    "# except for Ousidhoum in French and Arabic, where train set would otherwise be too small\n",
    "\n",
    "TEST_SIZE = 2500\n",
    "\n",
    "for dataset in df_dict:\n",
    "    if \"ousid\" in dataset:\n",
    "        df_dict[dataset], testset = train_test_split(df_dict[dataset], test_size = 1000, random_state=123)\n",
    "        testset.to_csv(f\"./data/1_clean/{dataset}/test_1000.csv\", index=False)\n",
    "    else:\n",
    "        df_dict[dataset], testset = train_test_split(df_dict[dataset], test_size = TEST_SIZE, random_state=123)\n",
    "        testset.to_csv(f\"./data/1_clean/{dataset}/test_{TEST_SIZE}.csv\", index=False)\n",
    "        \n",
    "# export all non-test data, so we can use it for active learning later\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset].to_csv(f\"./data/1_clean/{dataset}/train_{len(df_dict[dataset])}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38589148-db3a-4ae9-8b65-7cea81f12cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DYNABENCH2021_ENGLISH\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 5000 training set\n",
      "  saving n = 10000 training set\n",
      "  saving n = 20000 training set\n",
      "\n",
      "OUSIDHOUM2019_FRENCH\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "FORTUNA2019_PORTUGUESE\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "BASILE2019_SPANISH\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "OUSIDHOUM2019_ARABIC\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "SANGUINETTI2020_ITALIAN\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 5000 training set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create differently-sized train portions from rest of data\n",
    "\n",
    "SEEDS = 10 # for repeated experiments with different random data selection\n",
    "N_RANGE = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000]\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset.upper())\n",
    "    for n in N_RANGE:\n",
    "        if n<len(df_dict[dataset]):\n",
    "            print(f\"  saving n = {n} training set\")\n",
    "            for random_state in range(1, SEEDS+1):\n",
    "                df_dict[dataset].sample(n, random_state = random_state).to_csv(f\"./data/1_clean/{dataset}/train/train_{n}_rs{random_state}.csv\",index=False)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customisability-env",
   "language": "python",
   "name": "customisability-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
