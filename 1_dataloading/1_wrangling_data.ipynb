{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13adda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from html import unescape\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbcb7d-80d9-42c9-b391-cf6e785ae5eb",
   "metadata": {},
   "source": [
    "## Load raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751cc58c-ca94-42c7-b1bd-a1d1e23ebdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "san20_it\n",
      "for19_pt\n",
      "bas19_es\n",
      "ous19_ar\n",
      "dyn21_en\n",
      "ous19_fr\n"
     ]
    }
   ],
   "source": [
    "df_dict = dict()\n",
    "\n",
    "PATH = \"../0_data/main/0_raw\"\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if \"ipynb\" not in file:\n",
    "        print(re.sub('\\.csv$', '', file))\n",
    "        df_dict[re.sub('\\.csv$', '', file)] = pd.read_csv(f\"{PATH}/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7ed05-5188-48b5-a2ca-338ebadd806b",
   "metadata": {},
   "source": [
    "## Reformat columns\n",
    "Need separate logic for different datasets. 1 is for hateful, 0 for non-hateful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13277bd-80b3-4664-854c-9067973ff9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynabench 2021 / English\n",
    "df_dict[\"dyn21_en\"].label.replace({\"hate\":1, \"nothate\":0}, inplace=True)\n",
    "\n",
    "# Fortuna 2019 / Portuguese\n",
    "df_dict[\"for19_pt\"].rename(columns={\"hatespeech_comb\": \"label\"}, inplace=True)\n",
    "\n",
    "# Basile 2019 / Spanish\n",
    "df_dict[\"bas19_es\"].rename(columns={\"HS\": \"label\"}, inplace=True)\n",
    "\n",
    "# Sanguinetti 2020 / Italian\n",
    "df_dict[\"san20_it\"].rename(columns={\"hs\": \"label\"}, inplace=True)\n",
    "\n",
    "# Ousidhoum 2019 / Arabic & French\n",
    "for d in [\"ous19_ar\", \"ous19_fr\"]:\n",
    "    df_dict[d][\"label\"] = df_dict[d].sentiment.apply(lambda x: 1 if \"hateful\" in x else 0)\n",
    "    # text was already cleaned in a way that conflicts with our later cleaning, so we align it here\n",
    "    df_dict[d][\"text\"] = df_dict[d].tweet.apply(lambda x: x.replace(\"@url\", \"http\"))\n",
    "    \n",
    "# drop redundant columns\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset] = df_dict[dataset][[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb486c0-6d69-47de-ab40-1395cff48b78",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f2180b-49b9-4337-8bf6-918ae0fff373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = unescape(text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_-]+\",'@user',text) # format expected by XLM-T\n",
    "    text = re.sub(r\"http\\S+\",'http',text) # format expected by XLM-T\n",
    "    text = re.sub(r\"\\n\",' ',text)\n",
    "    text = re.sub(r\"\\t\",' ',text)\n",
    "    text = text.replace(\"[URL]\", \"http\") # format expected by XLM-T\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset][\"text\"] = df_dict[dataset].text.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f11a2-57a3-4f6e-85d8-1e9964695e8a",
   "metadata": {},
   "source": [
    "## Show descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf6ea87-7c69-4ead-88e6-7dd675650ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAN20_IT\n",
      "8100 entries, of which 3388 (41.83%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>@user sono persone di vari paesi europei,varie religioni e dunque anche musulmani.Isis contro ogni essere umano che vuole la libertà'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>RT Corriere \"Il rapper Bello Figo canta la vita \"comoda\" del profugo: e Mussolini ci casca … http http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>@user @user @user @user Rimandate tutti i migranti a casa loro.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>@user Per la nostra sicurezza bisogna identificare tutti quei fetidi di beduini islamici che sono andati davanti al colosseo e cacciarli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>#Piazzapulita:caro Formigli basta basta noi italiani siamo alla fame e voi ci rompete i coglioni con gli immigrati</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          text  \\\n",
       "2142     @user sono persone di vari paesi europei,varie religioni e dunque anche musulmani.Isis contro ogni essere umano che vuole la libertà'   \n",
       "919                                     RT Corriere \"Il rapper Bello Figo canta la vita \"comoda\" del profugo: e Mussolini ci casca … http http   \n",
       "4095                                                                           @user @user @user @user Rimandate tutti i migranti a casa loro.   \n",
       "3573  @user Per la nostra sicurezza bisogna identificare tutti quei fetidi di beduini islamici che sono andati davanti al colosseo e cacciarli   \n",
       "2928                        #Piazzapulita:caro Formigli basta basta noi italiani siamo alla fame e voi ci rompete i coglioni con gli immigrati   \n",
       "\n",
       "      label  \n",
       "2142      0  \n",
       "919       0  \n",
       "4095      1  \n",
       "3573      1  \n",
       "2928      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR19_PT\n",
      "5670 entries, of which 1788 (31.53%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>dps d ontem eu pensei assim q so qro uma sapatao p chamar d meu camiaozino de amor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Algumas razões para explicar o Fenômeno Bolsonaro @user  @user @user  http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>NÃO USO ISSO GOSTO DO TÉTE A TÉTE, CHEGA ENCOCHANDO E CHAMANDO DE DELÍCIA, UM AMANTE A MODA ANTIGA  #JoaquinResponde http</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>cara, pode me chamar do que quiser! Quero ver refutar o que falei com fatos, lógica e verdades! http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>RT @user: Quão 'democratas' e 'tolerantes' são estes esquerdistas, estes 'direitinhas' e estes 'politicamente correctos'.  http _</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   text  \\\n",
       "1211                                                 dps d ontem eu pensei assim q so qro uma sapatao p chamar d meu camiaozino de amor   \n",
       "299                                                          Algumas razões para explicar o Fenômeno Bolsonaro @user  @user @user  http   \n",
       "2917          NÃO USO ISSO GOSTO DO TÉTE A TÉTE, CHEGA ENCOCHANDO E CHAMANDO DE DELÍCIA, UM AMANTE A MODA ANTIGA  #JoaquinResponde http   \n",
       "796                                cara, pode me chamar do que quiser! Quero ver refutar o que falei com fatos, lógica e verdades! http   \n",
       "4823  RT @user: Quão 'democratas' e 'tolerantes' são estes esquerdistas, estes 'direitinhas' e estes 'politicamente correctos'.  http _   \n",
       "\n",
       "      label  \n",
       "1211      1  \n",
       "299       0  \n",
       "2917      1  \n",
       "796       0  \n",
       "4823      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BAS19_ES\n",
      "6600 entries, of which 2739 (41.50%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Cambio de junta directiva club activo 20-30 Colon Sur en Club Árabe http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>#MuyRicoMuyRicoPero pues te gusta cualquier gata pintada de güera. #D0nLuckyLuciano #MaffiaTeam http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>Espero que tengan un buen año y reciban lo que merezcan menos yo porque yo me jodería por puta JAJAJAJAJJAJAAJAJAJAJJAJAJAJA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>@user Es mierda licuada de perro, por que tu eres una perra no puede ser tuya. Si waaaa?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>@user Está pinche zorra cállate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              text  \\\n",
       "1057                                                      Cambio de junta directiva club activo 20-30 Colon Sur en Club Árabe http   \n",
       "1957                          #MuyRicoMuyRicoPero pues te gusta cualquier gata pintada de güera. #D0nLuckyLuciano #MaffiaTeam http   \n",
       "2772  Espero que tengan un buen año y reciban lo que merezcan menos yo porque yo me jodería por puta JAJAJAJAJJAJAAJAJAJAJJAJAJAJA   \n",
       "2419                                      @user Es mierda licuada de perro, por que tu eres una perra no puede ser tuya. Si waaaa?   \n",
       "4878                                                                                               @user Está pinche zorra cállate   \n",
       "\n",
       "      label  \n",
       "1057      0  \n",
       "1957      0  \n",
       "2772      0  \n",
       "2419      1  \n",
       "4878      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUS19_AR\n",
      "3353 entries, of which 755 (22.52%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>@user هي بقت عالثقافة بلد شكبرة كاعد يرجع ليورة مثل بول البعير يوم بعد يوم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>@user وجهة مزبلية مش سياحية ! شعب وسخ و ارض وسخة ! عيب عليكم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>@user @user مدري شفتي التحرش ؟!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>@user كلامك رائع وسليم لكن لماذا لاتتكلم عن عنصرية الفلسطينيين الذين يعايرون ابناء الحرمين في بول البعير و… @user</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>@user @user @user @user انت روح اشرب لك كوبين بول البعير بتاعكم وانت تبئه كويس انشاء الله… @user</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   text  \\\n",
       "3255                                         @user هي بقت عالثقافة بلد شكبرة كاعد يرجع ليورة مثل بول البعير يوم بعد يوم   \n",
       "1555                                                       @user وجهة مزبلية مش سياحية ! شعب وسخ و ارض وسخة ! عيب عليكم   \n",
       "827                                                                                     @user @user مدري شفتي التحرش ؟!   \n",
       "3333  @user كلامك رائع وسليم لكن لماذا لاتتكلم عن عنصرية الفلسطينيين الذين يعايرون ابناء الحرمين في بول البعير و… @user   \n",
       "371                    @user @user @user @user انت روح اشرب لك كوبين بول البعير بتاعكم وانت تبئه كويس انشاء الله… @user   \n",
       "\n",
       "      label  \n",
       "3255      0  \n",
       "1555      0  \n",
       "827       0  \n",
       "3333      0  \n",
       "371       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DYN21_EN\n",
      "41144 entries, of which 22175 (53.90%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>it is not ok to be a pikey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40252</th>\n",
       "      <td>i think most refugees would agree that rapists are scum of the earth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37263</th>\n",
       "      <td>It\u0019s not ok to discriminate gays but I'm really not fond of them</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40919</th>\n",
       "      <td>marriage is for bloody working class people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31456</th>\n",
       "      <td>Its name is kungflu not covid19 virus, it is hard to explain what is acceptable racism to those who only react when there is a discrimination against them.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                              text  \\\n",
       "548                                                                                                                                     it is not ok to be a pikey   \n",
       "40252                                                                                         i think most refugees would agree that rapists are scum of the earth   \n",
       "37263                                                                                             It\u0019s not ok to discriminate gays but I'm really not fond of them   \n",
       "40919                                                                                                                  marriage is for bloody working class people   \n",
       "31456  Its name is kungflu not covid19 virus, it is hard to explain what is acceptable racism to those who only react when there is a discrimination against them.   \n",
       "\n",
       "       label  \n",
       "548        1  \n",
       "40252      0  \n",
       "37263      1  \n",
       "40919      0  \n",
       "31456      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUS19_FR\n",
      "4014 entries, of which 399 (9.94%) are hateful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>un attardé qui ne comprend rien à l'anglais et parle le français comme ribery.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>@user tu ja respondeu mongol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>@user j...avais grave besoin d...entendre ca merci mec !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>hier soir je ss fait insulté de «sale pd de merde» parce qu’un renoi aigri commandé un filet-o-fish à 1h45am d… http</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>@user et fais moi pas dire ce que j’ai pas dis l’afrique appartient au africain donc au renois et au maghrébin un malade toi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              text  \\\n",
       "2940                                                un attardé qui ne comprend rien à l'anglais et parle le français comme ribery.   \n",
       "1625                                                                                                  @user tu ja respondeu mongol   \n",
       "1952                                                                      @user j...avais grave besoin d...entendre ca merci mec !   \n",
       "2880          hier soir je ss fait insulté de «sale pd de merde» parce qu’un renoi aigri commandé un filet-o-fish à 1h45am d… http   \n",
       "605   @user et fais moi pas dire ce que j’ai pas dis l’afrique appartient au africain donc au renois et au maghrébin un malade toi   \n",
       "\n",
       "      label  \n",
       "2940      0  \n",
       "1625      0  \n",
       "1952      0  \n",
       "2880      0  \n",
       "605       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def descriptive_stats(df):\n",
    "    n_total = df.shape[0]\n",
    "    n_hate = df.label.sum()\n",
    "    print(\"{} entries, of which {} ({:.2%}) are hateful.\".format(n_total, n_hate, n_hate/n_total))\n",
    "    return df.label.sum()/len(df), len(df)\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset.upper())\n",
    "    descriptive_stats(df_dict[dataset])\n",
    "    display(df_dict[dataset].sample(5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c79d7f-8abc-4b7b-957d-073051f468fe",
   "metadata": {},
   "source": [
    "## Create and export splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d2e82a-460f-4fe4-b777-fe34ae08c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside 2k from each dataset for testing and 500 for dev\n",
    "# except for Ousidhoum in French and Arabic, where train set would otherwise be too small\n",
    "\n",
    "TEST_SIZE = 2000\n",
    "DEV_SIZE = 500\n",
    "\n",
    "for dataset in df_dict:\n",
    "    if \"ous19_fr\" in dataset:\n",
    "        df_dict[dataset], devtest = train_test_split(df_dict[dataset], test_size = 2000, random_state=123)\n",
    "        devset, testset = train_test_split(devtest, test_size = 1500, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_500.csv\", index=False)\n",
    "        testset.to_csv(f\"../0_data/main/1_clean/{dataset}/test_1500.csv\", index=False)\n",
    "    elif \"ous19_ar\" in dataset:\n",
    "        df_dict[dataset], devtest = train_test_split(df_dict[dataset], test_size = 1300, random_state=123)\n",
    "        devset, testset = train_test_split(devtest, test_size = 1000, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_300.csv\", index=False)\n",
    "        testset.to_csv(f\"../0_data/main/1_clean/{dataset}/test_1000.csv\", index=False)\n",
    "    else:\n",
    "        df_dict[dataset], devtest = train_test_split(df_dict[dataset], test_size = TEST_SIZE+DEV_SIZE, random_state=123)\n",
    "        devset, testset = train_test_split(devtest, test_size = TEST_SIZE, random_state=123)\n",
    "        devset.to_csv(f\"../0_data/main/1_clean/{dataset}/dev_{DEV_SIZE}.csv\", index=False)\n",
    "        testset.to_csv(f\"../0_data/main/1_clean/{dataset}/test_{TEST_SIZE}.csv\", index=False)\n",
    "        \n",
    "# export all data that is not test or dev, so we can use it for active learning later\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset].to_csv(f\"../0_data/main/1_clean/{dataset}/train_{len(df_dict[dataset])}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38589148-db3a-4ae9-8b65-7cea81f12cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAN20_IT\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "FOR19_PT\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "BAS19_ES\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "OUS19_AR\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "DYN21_EN\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 3000 training set\n",
      "  saving n = 4000 training set\n",
      "  saving n = 5000 training set\n",
      "  saving n = 10000 training set\n",
      "  saving n = 20000 training set\n",
      "\n",
      "OUS19_FR\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 30 training set\n",
      "  saving n = 40 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 300 training set\n",
      "  saving n = 400 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create differently-sized train portions from rest of data\n",
    "\n",
    "SEEDS = 10 # for repeated experiments with different random data selection\n",
    "N_RANGE = [10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000, 10000, 20000]\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset.upper())\n",
    "    for n in N_RANGE:\n",
    "        \n",
    "        # save all splits for Dynabench\n",
    "        if n<len(df_dict[dataset]) and \"dyn21\" in dataset: \n",
    "            print(f\"  saving n = {n} training set\")\n",
    "            for random_state in range(1, SEEDS+1):\n",
    "                df_dict[dataset].sample(n, random_state = random_state).to_csv(f\"../0_data/main/1_clean/{dataset}/train/train_{n}_rs{random_state}.csv\",index=False)\n",
    "        \n",
    "        # save splits up to 2k for other datasets\n",
    "        elif n<len(df_dict[dataset]) and n<=2000: \n",
    "            print(f\"  saving n = {n} training set\")\n",
    "            for random_state in range(1, SEEDS+1):  \n",
    "                df_dict[dataset].sample(n, random_state = random_state).to_csv(f\"../0_data/main/1_clean/{dataset}/train/train_{n}_rs{random_state}.csv\",index=False)\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
