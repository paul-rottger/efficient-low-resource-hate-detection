{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e52f643-722a-4c96-8e5c-bb4381a4c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f6eaf-ab02-4ebb-bf42-94500c3cf5d2",
   "metadata": {},
   "source": [
    "## Uncertainty-based active learning for data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e6eee8-0f28-4076-8863-429d98930519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes we have model predictions (pred_label) and uncertainty (pred_score) for each entry\n",
    "# could also do cross-entropy for uncertainty\n",
    "# we only use the train set\n",
    "# the test set remains completely held-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4672ac29-6686-4ed0-8811-f1e9c472e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ousidhoum2019_french\n",
      "loading ousidhoum2019_arabic\n",
      "loading fortuna2019_portuguese\n",
      "loading sanguinetti2020_italian\n",
      "loading basile2019_spanish\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./data/1_clean\"\n",
    "\n",
    "df_dict = dict()\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if \"ipynb\" not in file and \"english\" not in file:\n",
    "        print(f\"loading {file}\")\n",
    "        for file2 in os.listdir(f\"{PATH}/{file}\"):\n",
    "            if \"train_\" in file2:\n",
    "                df_dict[file] = pd.read_csv(f\"{PATH}/{file}/{file2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "362abd89-da67-4e00-8b31-d1b08ac87619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy column for uncertainty while waiting for real results\n",
    "for dataset in df_dict:\n",
    "    df_dict[dataset][\"pred_score\"] = df_dict[dataset].label.apply(lambda x: random.uniform(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46d968c7-d5aa-4f3b-a248-48dcd3e6931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ousidhoum2019_french\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "ousidhoum2019_arabic\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "fortuna2019_portuguese\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n",
      "sanguinetti2020_italian\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "  saving n = 5000 training set\n",
      "\n",
      "basile2019_spanish\n",
      "  saving n = 10 training set\n",
      "  saving n = 20 training set\n",
      "  saving n = 50 training set\n",
      "  saving n = 100 training set\n",
      "  saving n = 200 training set\n",
      "  saving n = 500 training set\n",
      "  saving n = 1000 training set\n",
      "  saving n = 2000 training set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select top-n entries based on active learning\n",
    "# this is deterministic, so no need for multiple random seeds\n",
    "\n",
    "N_RANGE = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000]\n",
    "\n",
    "for dataset in df_dict:\n",
    "    print(dataset)\n",
    "    df_dict[dataset].sort_values(by=\"pred_score\", inplace=True)\n",
    "    for n in N_RANGE:\n",
    "        if n<len(df_dict[dataset]):\n",
    "            print(f\"  saving n = {n} training set\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214e29b-d2a6-4eb9-9754-121694c16280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customisability-env",
   "language": "python",
   "name": "customisability-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
